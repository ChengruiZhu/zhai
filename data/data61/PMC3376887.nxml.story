What is the nature of the representations acquired in implicit statistical
learning? Recent results in the field of language learning have shown that
adults and infants are able to find the words of an artificial language when
exposed to a continuous auditory sequence consisting in a random ordering of
these words. Such performance can only be based on processing the transitional
probabilities between sequence elements. Two different kinds of mechanisms may
account for these data: Participants may either parse the sequence into smaller
chunks corresponding to the words of the artificial language, or they may become
progressively sensitive to the actual values of the transitional probabilities
between syllables. The two accounts are difficult to differentiate because they
make similar predictions in comparable experimental settings. In this study, we
present two experiments that aimed at contrasting these two theories. In these
experiments, participants had to learn 2 sets of pseudo-linguistic regularities:
Language 1 (L1) and Language 2 (L2) presented in the context of a serial
reaction time task. L1 and L2 were either unrelated (none of the syllabic
transitions of L1 were present in L2), or partly related (some of the
intra-words transitions of L1 were used as inter-words transitions of L2). The
two accounts make opposite predictions in these two settings. Our results
indicate that the nature of the representations depends on the learning
condition. When cues were presented to facilitate parsing of the sequence,
participants learned the words of the artificial language. However, when no cues
were provided, performance was strongly influenced by the employed transitional
probabilities.