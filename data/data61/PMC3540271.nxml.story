Central auditory processing in humans was investigated by comparing the perceptual effects of temporal parameters of electrical stimulation in auditory midbrain implant (AMI) and cochlear implant (CI) users. Four experiments were conducted to measure the following: effect of interpulse intervals on detection thresholds and loudness; temporal modulation transfer functions (TMTFs); effect of duration on detection thresholds; and forward masking decay. The CI data were consistent with a phenomenological model that based detection or loudness decisions on the output of a sliding temporal integration window, the input to which was the hypothetical auditory nerve response to each stimulus pulse. To predict the AMI data, the model required changes to both the neural response input (i.e., midbrain activity to AMI stimuli, compared to auditory nerve activity to CI stimuli) and the shape of the integration window. AMI data were consistent with a neural response that decreased more steeply compared to CI stimulation as the pulse rate increased or interpulse interval decreased. For one AMI subject, the data were consistent with a significant adaptation of the neural response for rates above 200Â Hz. The AMI model required an integration window that was significantly wider (i.e., decreased temporal resolution) than that for CI data, the latter being well fit using the same integration window shape as derived from normal-hearing data. These models provide a useful way to conceptualize how stimulation of central auditory structures differs from stimulation of the auditory nerve and to better understand why AMI users have difficulty processing temporal cues important for speech understanding.