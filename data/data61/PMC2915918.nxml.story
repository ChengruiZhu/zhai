The neural mechanisms underlying primate locomotion are largely unknown. While behavioral and theoretical work has provided a number of ideas of how navigation is controlled, progress will require direct physiolgical tests of the underlying mechanisms. In turn, this will require development of appropriate animal models. We trained three monkeys to track a moving visual target in a simple virtual environment, using a joystick to control their direction. The monkeys learned to quickly and accurately turn to the target, and their steering behavior was quite stereotyped and reliable. Monkeys typically responded to abrupt steps of target direction with a biphasic steering movement, exhibiting modest but transient overshoot. Response latencies averaged approximately 300 ms, and monkeys were typically back on target after about 1 s. We also exploited the variability of responses about the mean to explore the time-course of correlation between target direction and steering response. This analysis revealed a broad peak of correlation spanning approximately 400 ms in the recent past, during which steering errors provoke a compensatory response. This suggests a continuous, visual-motor loop controls steering behavior, even during the epoch surrounding transient inputs. Many results from the human literature also suggest that steering is controlled by such a closed loop. The similarity of our results to those in humans suggests the monkey is a very good animal model for human visually guided steering.