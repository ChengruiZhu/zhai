We measured perceived depth from the optic flow (a) when showing a stationary
physical or virtual object to observers who moved their head at a normal or
slower speed, and (b) when simulating the same optic flow on a computer and
presenting it to stationary observers. Our results show that perceived surface
slant is systematically distorted, for both the active and the passive viewing
of physical or virtual surfaces. These distortions are modulated by head
translation speed, with perceived slant increasing directly with the local
velocity gradient of the optic flow. This empirical result allows us to
determine the relative merits of two alternative approaches aimed at explaining
perceived surface slant in active vision: an “inverse optics” model
that takes head motion information into account, and a probabilistic model that
ignores extra-retinal signals. We compare these two approaches within the
framework of the Bayesian theory. The “inverse optics” Bayesian
model produces veridical slant estimates if the optic flow and the head
translation velocity are measured with no error; because of the influence of a
“prior” for flatness, the slant estimates become systematically
biased as the measurement errors increase. The Bayesian model, which ignores the
observer's motion, always produces distorted estimates of surface slant.
Interestingly, the predictions of this second model, not those of the first one,
are consistent with our empirical findings. The present results suggest that (a)
in active vision perceived surface slant may be the product of probabilistic
processes which do not guarantee the correct solution, and (b) extra-retinal
signals may be mainly used for a better measurement of retinal information.