At the onset of visually ambiguous or conflicting stimuli, our visual system quickly ‘chooses’ one of the possible percepts. Interrupted presentation of the same stimuli has revealed that each percept-choice depends strongly on the history of previous choices and the duration of the interruptions. Recent psychophysics and modeling has discovered increasingly rich dynamical structure in such percept-choice sequences, and explained or predicted these patterns in terms of simple neural mechanisms: fast cross-inhibition and slow shunting adaptation that also causes a near-threshold facilitatory effect. However, we still lack a clear understanding of the dynamical interactions between two distinct, temporally interleaved, percept-choice sequences—a type of experiment that probes which feature-level neural network connectivity and dynamics allow the visual system to resolve the vast ambiguity of everyday vision. Here, we fill this gap. We first show that a simple column-structured neural network captures the known phenomenology, and then identify and analyze the crucial underlying mechanism via two stages of model-reduction: A 6-population reduction shows how temporally well-separated sequences become coupled via adaptation in neurons that are shared between the populations driven by either of the two sequences. The essential dynamics can then be reduced further, to a set of iterated adaptation-maps. This enables detailed analysis, resulting in the prediction of phase-diagrams of possible sequence-pair patterns and their response to perturbations. These predictions invite a variety of future experiments.