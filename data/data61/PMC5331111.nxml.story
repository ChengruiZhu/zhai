Approximately 1 in 3–4 patients presenting with an ischemic stroke will also have atrial fibrillation (AF), and AF-related strokes can be effectively prevented using oral anticoagulant therapy (OAC), either with well-controlled vitamin K antagonists (VKAs) or non-vitamin K antagonist oral anticoagulants (NOACs). In addition, OAC use (both VKAs and NOACs) is associated with a 26% reduction in all-cause mortality (VKAs) or an additional 10% mortality reduction with NOACs relative to VKAs. The decision to use OAC in individual AF patient is based on the estimated balance of the benefit from ischemic stroke reduction against the risk of major OAC-related bleeding [essentially intracranial hemorrhage (ICH)]. Better appreciation of the importance of VKAs’ anticoagulation quality [a target time in therapeutic range (TTR) of ≥70%] and the availability of NOACs (which offer better safety compared to VKAs) have decreased the estimated threshold for OAC treatment in AF patients towards lower stroke risk levels. Still, contemporary registry-based data show that OAC is often underused in AF patients at increased risk of stroke. The uncertainty whether to use OAC may be particularly pronounced in AF patients with a single additional stroke risk factor, who are often (mis)perceived as having a “borderline” or insufficient stroke risk to trigger the use of OAC. However, observational data from real-world AF cohorts show that the annual stroke rates in such patients are higher than in patients with no additional stroke risk factors, and OAC use has been associated with reduction in stroke, systemic embolism, or death in comparison to no therapy or aspirin, with no increase in the risk of bleeding relative to aspirin. In this review article, we summarize the basic principles of stroke risk stratification in AF patients and discuss contemporary real-world evidence on OAC use and outcomes of OAC treatment in AF patients with a single additional stroke risk factor in various real-world AF cohorts.