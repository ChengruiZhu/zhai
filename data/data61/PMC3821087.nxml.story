Tilt table test (TTT) is a standard examination for patients with suspected autonomic nervous system (ANS) dysfunction or uncertain causes of syncope. Currently, the analytical method based on blood pressure (BP) or heart rate (HR) changes during the TTT is linear but normal physiological modulations of BP and HR are thought to be predominately nonlinear. Therefore, this study consists of two parts: the first part is analyzing the HR during TTT which is compared to three methods to distinguish normal controls and subjects with ANS dysfunction. The first method is power spectrum density (PSD), while the second method is detrended fluctuation analysis (DFA), and the third method is multiscale entropy (MSE) to calculate the complexity of system. The second part of the study is to analyze BP and cerebral blood flow velocity (CBFV) changes during TTT. Two measures were used to compare the results, namely correlation coefficient analysis (nMxa) and MSE. The first part of this study has concluded that the ratio of the low frequency power to total power of PSD, and MSE methods are better than DFA to distinguish the difference between normal controls and patients groups. While in the second part, the nMxa of the three stages moving average window is better than the nMxa with all three stages together. Furthermore the analysis of BP data using MSE is better than CBFV data.