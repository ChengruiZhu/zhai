Object files play important roles in visual cognition, one of which is feature integration. However, their internal structure remains unknown. The current study investigated how multiple features of an object—color and shape—are integrated using a modified object-reviewing paradigm. In particular, we tested whether independent features or color-shape conjunction are bound to the file. A preview of two-colored objects was followed by a linking display. Then, a target was presented to judge whether the target contains any feature of the previews, regardless of their locations. Conditions in which both color and shape are matched with different corresponding preview locations were compared. If features are independently bound, facilitation in response time (RT) will increase additively as the number of location-shared features. If features are bundled, the RT facilitation occurs only when both features share the location. A series of experiments different in stimuli, the number of placeholders, and object motion showed different patterns of mean RT, but RT distribution analysis indicated that estimated nondecision time is consistent with the feature bundle hypothesis. The conjunction-based object preview benefit suggests that in object file formation, color and shape form a perceptual unit, and the unit is kept through object motion.