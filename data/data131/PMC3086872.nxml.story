The researchers searched literature databases and reference lists, consulted
experts, and hand-searched various other sources for studies in which the
pooled estimate of an adverse effect from RCTs could be directly compared to
the pooled estimate for the same adverse effect from observational studies.
They identified 19 studies that together covered 58 separate adverse
effects. In almost all instances, the estimates of harm obtained from
meta-analyses of RCTs and observational studies had overlapping 95%
confidence intervals. That is, in statistical terms, the estimates of harm
were similar. Moreover, in nearly two-thirds of cases, there was agreement
between RCTs and observational studies about whether a treatment caused a
significant increase in adverse effects, a significant decrease, or no
significant change (a significant change is one unlikely to have occurred by
chance). Finally, the researchers used meta-analysis to calculate that the
pooled ratio of the odds ratios (a statistical measurement of risk) of RCTs
compared to observational studies was 1.03. This figure suggests that there
was no consistent difference between risk estimates obtained from
meta-analysis of RCT data and those obtained from meta-analysis of
observational study data.