Neuronal models of perceptual learning often focus on the feedforward information stream extending from the primary sensory area up to the prefrontal cortex. In these models, the stimulus representation in the sensory area remains unchanged during learning while higher cortical areas adapt the read out of the relevant stimulus information. An alternative view of perceptual learning is that the sensory representation at the very early cortical stage is modified by an adaptable top-down signal emerging from a higher cortical area. In this view, the sensory representation during perceptual training is sharpened by an internal signal which can be turned on or off depending on the task. We show how this top-down view explains improvements in interval discrimination by modifying contextual interactions in the primary visual cortex (V1). Without such top-down signal the V1 interactions support surface segmentation as it is typically used in visual scene analysis. During an interval discrimination task, however, a top-down signal which globally increases the gain of V1 neurons sharpens the V1 circuitry for this specific task. Although the top-down signal acts through a simple gain increase, the signal can change the tuning curves of V1 neurons embedded in a recurrent circuitry in a rather complex way.