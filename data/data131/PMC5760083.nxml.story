Insects, with their limited brain resources and high performance in a wide behavioral repertoire, are exquisite model systems for studying parsimonious signal processing. They extract spatial information by actively shaping their self-motion (e.g. when performing peering movements or during flight segments with fixed gaze) and estimate distance according to the speed of the resulting retinal displacements. The computation of retinal speed is accomplished by arrays of motion detector circuits retinotopically arranged in the second neuropile layer of the visual system. Sharing general adaptive response characteristics with other neurons and neuronal circuits, the responses of motion detectors depend on stimulus history. In the present study, we developed a novel adaptive model of the visual motion pathway of insects and analyzed the consequences of motion adaptation for computing spatial information about the 3D environment. We found that motion adaptation facilitates the segregation of nearby objects from their cluttered background during dynamic locomotion. The functional significance of motion adaptation is likely to generalize to optic flow-based spatial vision in other animals, and the motion adaptation mechanism implemented in our model could also be useful for artificial visual systems.