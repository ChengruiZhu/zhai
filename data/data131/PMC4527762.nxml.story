An animal exploring a natural scene receives sensory inputs that vary, rapidly, over many orders of magnitude. Neurons must transmit these inputs faithfully despite both their limited dynamic range and relatively slow adaptation time scales. One well-accepted strategy for transmitting signals through limited dynamic range channels–predictive coding–transmits only components of the signal that cannot be predicted from the past. Predictive coding algorithms respond maximally to unexpected inputs, making them appealing in describing sensory transmission. However, recent experimental evidence has shown that neuronal circuits adapt quickly, to respond optimally following rapid input changes. Here, we reconcile the predictive coding algorithm with this automatic adaptation, by introducing a fixed nonlinearity into a predictive coding circuit. The resulting network automatically “adapts” its linearized response to different inputs. Indeed, it approximates the performance of an optimal linear circuit implementing predictive coding, without having to vary its internal parameters. Further, adding this nonlinearity to the predictive coding circuit still allows the input to be compressed losslessly, allowing for additional downstream manipulations. Finally, we demonstrate that the nonlinear circuit dynamics match responses in both auditory and visual neurons. Therefore, we believe that this nonlinear circuit may be a general circuit motif that can be applied in different neural circuits, whenever it is necessary to provide an automatic improvement in the quality of the transmitted signal, for a fast varying input distribution.