Thermal waves are caused by pure diffusion: their amplitude is decreased by more than a factor of 500 within a propagation distance of one wavelength. The diffusion equation, which describes the temperature as a function of space and time, is linear. For every linear equation the superposition principle is valid, which is known as Huygens principle for optical or mechanical wave fields. This limits the spatial resolution, like the Abbe diffraction limit in optics. The resolution is the minimal size of a structure which can be detected at a certain depth. If an embedded structure at a certain depth in a sample is suddenly heated, e.g., by eddy current or absorbed light, an image of the structure can be reconstructed from the measured temperature at the sample surface. To get the resolution the image reconstruction can be considered as the time reversal of the thermal wave. This inverse problem is ill-conditioned and therefore regularization methods have to be used taking additional assumptions like smoothness of the solutions into account. In the present work for the first time, methods of non-equilibrium statistical physics are used to solve this inverse problem without the need of such additional assumptions and without the necessity to choose a regularization parameter. For reconstructing such an embedded structure by thermal waves the resolution turns out to be proportional to the depth and inversely proportional to the natural logarithm of the signal-to-noise ratio. This result could be derived from the diffusion equation by using a delta-source at a certain depth and setting the entropy production caused by thermal diffusion equal to the information loss. No specific model about the stochastic process of the fluctuations and about the distribution densities around the mean values was necessary to get this result.