Universal oral iron supplementation, undertaken according to 1998 WHO guidelines, produced adverse consequences among some children in malaria-endemic areas. Prompted by the Pemba trial, which revealed excessive hospitalizations and deaths, WHO advised that iron supplementation in such regions be accompanied by previous screening for iron deficiency. This agenda, however, poses issues of cost, benefit, acceptability, technical feasibility, and reliability of such screening. The cost of equipment and personnel is balanced against savings from iron supplements spared and treatment for morbidity averted. Costs aside, the most efficacious acceptable screening approach for avoiding hospitalization and deaths must be fielded. Screening before supplementation can be used to assess hematological, iron, and possible inflammatory status to differentiate the source of decreased hemoglobin concentration. Iron deficiency has often been inferred from hematological status markers. The need for extraction of blood, albeit capillary in origin, and high assay costs limit the use of validated methods in screening. Noninvasive methods, i.e., not requiring the extraction of blood, provide the most acceptable and potentially least expensive approach for determining hematological or iron status. Although a noninvasive technique for iron and inflammatory status would be the ideal, it is unattained. Field-friendly, skin-probe hemoglobin devices, derived from instruments for clinical settings, are being developed and tested for eventual rollout in malarial areas. Given a firm grounding for the theoretical requirements needed to advance the screening agenda, evaluation and monitoring of the performance of screening devices can proceed hand in hand.