Reading aloud involves computing the sound of a word from its visual form. This may be accomplished 1) by direct associations between spellings and phonology and 2) by computation from orthography to meaning to phonology. These components have been studied in behavioral experiments examining lexical properties such as word frequency; length in letters or phonemes; spelling–sound consistency; semantic factors such as imageability, measures of orthographic, or phonological complexity; and others. Effects of these lexical properties on specific neural systems, however, are poorly understood, partially because high intercorrelations among lexical factors make it difficult to determine if they have independent effects. We addressed this problem by decorrelating several important lexical properties through careful stimulus selection. Functional magnetic resonance imaging data revealed distributed neural systems for mapping orthography directly to phonology, involving left supramarginal, posterior middle temporal, and fusiform gyri. Distinct from these were areas reflecting semantic processing, including left middle temporal gyrus/inferior-temporal sulcus, bilateral angular gyrus, and precuneus/posterior cingulate. Left inferior frontal regions generally showed increased activation with greater task load, suggesting a more general role in attention, working memory, and executive processes. These data offer the first clear evidence, in a single study, for the separate neural correlates of orthography–phonology mapping and semantic access during reading aloud.